{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from arcgis.gis import GIS\n",
    "import arcpy\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to common data locations - NOTE: to convert any path to a raw string, simply use str(path_instance)\n",
    "project_parent = Path('./').absolute().parent\n",
    "\n",
    "data_dir = project_parent/'data'\n",
    "\n",
    "data_raw = data_dir/'raw'\n",
    "data_ext = data_dir/'external'\n",
    "data_int = data_dir/'interim'\n",
    "data_out = data_dir/'processed'\n",
    "\n",
    "gdb_raw = data_raw/'raw.gdb'\n",
    "gdb_int = data_int/'interim.gdb'\n",
    "gdb_out = data_out/'processed.gdb'\n",
    "\n",
    "# import the project package from the project package path\n",
    "# ideally will be imported using 'from arcgis import da'\n",
    "sys.path.append(str(project_parent/'src'))\n",
    "import dm\n",
    "\n",
    "# load the \"autoreload\" extension so that code can change, & always reload modules so that as you change code in src, it gets loaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introspectivley Examine and Get Geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get available resources, and show which is currently active\n",
    "dm.env.data.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data source\n",
    "dm.env.data.source = 'LOCAL'\n",
    "# dm.env.data.source = <GIS object instance>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discover what countries are available, and get country objects back\n",
    "cntry_df = dm.countries\n",
    "\n",
    "cntry_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a country...\n",
    "\n",
    "# ...by the country order...\n",
    "usa = countries[0]\n",
    "\n",
    "# ...or by the three letter identifier\n",
    "usa = ba.Country('USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the geographic resolutions available for the country as a dataframe from smallest to largest\n",
    "geos = usa.geographies\n",
    "\n",
    "geos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the lowest geographic resolution available for the most granular analysis\n",
    "\n",
    "# ...by index...\n",
    "geo_0_df = usa.get_geography(0)\n",
    "\n",
    "# ...by name\n",
    "geo_0_df = usa.get_geography('block_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the aoi using a similar method with a little method chaining\n",
    "aoi = usa.get_geography('cbsa').select('Seattle')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the block groups in the area of interest\n",
    "origin_geo_df = geo_df.spatial.within.(aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the store locations from the business listings\n",
    "loc_brand_df = usa.business.search('Ace Hardware')\n",
    "\n",
    "# ...and since returning a sptatially enabled dataframe, can use spatial.to_featureclass to save directly with function chaining\n",
    "usa.business.search('Ace Hardware').spatial.to_featureclass(gdb_int/'loc_brand')\n",
    "\n",
    "loc_brand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the competitors for the area of interest\n",
    "\n",
    "# ...by NAICS or SIC code...\n",
    "loc_comp_df = usa.business.get_competitors(\n",
    "    code=44413005,  # include ablity to specify shorted codes since NAICS codes can be shorter to be more general\n",
    "    code_type='NAICS', \n",
    "    brand_exclude='Ace Hardware'\n",
    ")\n",
    "\n",
    "# ...or simplly by looking up using the existing location brand layer as a template\n",
    "loc_comp_df = usa.business.get_competitors(brand_locations=loc_brand_df)\n",
    "\n",
    "# ...and since returning a sptatially enabled dataframe, can use spatial.to_featureclass to save directly with function chaining\n",
    "usa.business.get_competitors(brand_locations=loc_brand_df).spatial.to_featureclass(gdb_int/'loc_comp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Proximity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the origin to nth destinations table for brand locations\n",
    "prox_df_brand = dm.proximity.get_neareset_nth_locations(\n",
    "    origin_features=orgin_geo_df,\n",
    "    origin_id_column='ID',                                      \n",
    "    origin_centroid_weighting_features='path-to-block-points',  # features used to calculate a population weighted centroid location for routing\n",
    "    origin_centroid_weighting_column='POP',                     # used to weight each population feature for centroid calculation\n",
    "    destination_locations=loc_brand_df,\n",
    "    destination_id_column='STORE_ID'\n",
    "    destination_brand_or_concept_column='STORE_CONCEPT',              # think Nike Outlet versus Nike Brand Store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the origin to nth destinations table for brand locations\n",
    "prox_df_brand = dm.proximity.get_neareset_nth_locations(\n",
    "    origin_features=orgin_geo_df,\n",
    "    origin_id_column='ID',                                      \n",
    "    origin_centroid_weighting_features='path-to-block-points',  # features used to calculate a population weighted centroid location for routing\n",
    "    origin_centroid_weighting_column='POP',                     # used to weight each population feature for centroid calculation\n",
    "    destination_locations=loc_comp_df,\n",
    "    destination_id_column='LOCNUM'\n",
    "    destination_brand_or_concept_column='CONAME',               # think Nike Outlet versus Nike Brand Store\n",
    ")\n",
    "\n",
    "# ...and can even chain to create output using dataframe to_... functions\n",
    "prox_df_brand = dm.proximity.get_neareset_nth_locations(orgin_geo_df, 'ID', 'path-to-block-points', 'POP', loc_comp_df, 'LOCNUM', 'CONAME').to_csv('prox_df_brand.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discoveer what enrichment data is available\n",
    "enrich_df = dm.enrich.variables\n",
    "\n",
    "enrich_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrich origins with large number of variables\n",
    "\n",
    "# ...by just getting all of them...\n",
    "origin_enrich_df = dm.enrich.enrich_data(origin_geo_df, all_varaibles=True)\n",
    "\n",
    "# ...or by specifying category/categories...\n",
    "origin_enrich_df = dm.enrich.enrich_data(orgin_geo_df, variable_categories='key_variables')\n",
    "origin_enrich_df = dm.enrich.enrich_data(orgin_geo_df, variable_categories=['key_variables', 'agebyrace'])\n",
    "\n",
    "# ...or even chain the output using dataframe to_parquet or to_csv method\n",
    "dm.enrich.enrich_data(orgin_geo_df, variable_categories='key_variables').to_parquet(dir_int/'origin_enrich.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
